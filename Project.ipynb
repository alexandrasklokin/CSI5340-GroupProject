{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.25, 0.5, 0.25), (0.25, 0.25, 0.5), (0.5, 0.25, 0.25)]\n"
     ]
    }
   ],
   "source": [
    "# Code cell intended for imports and global settings.\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from SupportClasses import ModelSupport as ms, EnvironmentSetup as env\n",
    "\n",
    "# Global values\n",
    "NUMBER_OF_NODES = 3     # We only support values between 2 and 4 at present.\n",
    "NUMBER_OF_EPOCHS = 5\n",
    "\n",
    "# Model specific values\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Data distributions based on the number of nodes.\n",
    "data_distribution = env.data_distribution(NUMBER_OF_NODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "ConvNet(\n  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  (fc1): Linear(in_features=1568, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=10, bias=True)\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code cell is to be used for importing data and setting up the model.\n",
    "train_loader, validation_loader, test_loader = env.download_mnist()\n",
    "# Create and load the models. We initiate the model with None as we will update it with the global model in each round.\n",
    "fed_models = {f\"Federated_Model_{i+1}\": ms.FederatedModel(train_loader, validation_loader, None)\n",
    "                for i in range(NUMBER_OF_NODES)}\n",
    "\n",
    "# Create the baseline, non-federated model.\n",
    "baseline_model = ms.ConvNet(len(train_loader.dataset.dataset.classes))\n",
    "# Create the federated model\n",
    "federated_model = ms.ConvNet(len(train_loader.dataset.dataset.classes))\n",
    "\n",
    "# Send the models to the CUDA device if it exists.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "baseline_model.to(device=device)\n",
    "federated_model.to(device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model training complete.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: We need to get the length of all the datasets\n",
    "\n",
    "# Here we train a baseline model on all data. No federation as our baseline.\n",
    "path = 'baseline-model.pt'\n",
    "optimizer = optim.Adam(baseline_model.parameters())\n",
    "\n",
    "# We train a new model, if the model does not already exist in memory.\n",
    "if not os.path.exists(path):\n",
    "    for epoch in range(NUMBER_OF_EPOCHS):\n",
    "        start_time = time.time()\n",
    "        train_loss, train_acc = ms.train(baseline_model, train_loader, optimizer, criterion, device=device)\n",
    "        valid_loss, valid_acc = ms.test(baseline_model, validation_loader, criterion, device=device)\n",
    "        end_time = time.time()\n",
    "        # Get the time to perform non-federated learning\n",
    "        epoch_mins, epoch_secs = ms.epoch_time(start_time, end_time)\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Model name: Baseline Model | Epoch time (Baseline Training): {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.5f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.5f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    torch.save(baseline_model.state_dict(), path)\n",
    "print(\"Baseline model training complete.\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Model name: Federated_Model_1\n",
      "\tTrain Loss: 0.00189 | Train Acc: 98.54%\n",
      "\t Val. Loss: 0.00045 |  Val. Acc: 98.62%\n",
      "Epoch: 01 | Model name: Federated_Model_2\n",
      "\tTrain Loss: 0.00183 | Train Acc: 98.57%\n",
      "\t Val. Loss: 0.00054 |  Val. Acc: 98.36%\n",
      "Epoch: 01 | Model name: Federated_Model_3\n",
      "\tTrain Loss: 0.00196 | Train Acc: 98.55%\n",
      "\t Val. Loss: 0.00046 |  Val. Acc: 98.63%\n",
      "Epoch: 01 | Model name: Federated Average | Epoch time (Federated Training): 0m 58s\n",
      "\tTrain Loss: 0.00196 | Train Acc: 98.55%\n",
      "\t Val. Loss: 0.02016 |  Val. Acc: 33.40%\n",
      "Epoch: 02 | Model name: Federated_Model_1\n",
      "\tTrain Loss: 0.00130 | Train Acc: 99.04%\n",
      "\t Val. Loss: 0.00045 |  Val. Acc: 98.71%\n",
      "Epoch: 02 | Model name: Federated_Model_2\n",
      "\tTrain Loss: 0.00129 | Train Acc: 99.03%\n",
      "\t Val. Loss: 0.00041 |  Val. Acc: 98.93%\n",
      "Epoch: 02 | Model name: Federated_Model_3\n",
      "\tTrain Loss: 0.00132 | Train Acc: 98.96%\n",
      "\t Val. Loss: 0.00051 |  Val. Acc: 98.42%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-5-664007c2bfad>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     21\u001B[0m     \u001B[0mfederated_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mms\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfederated_averaging\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfed_models\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlen_model\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[1;31m# Validate this model on a, small balanced validation set\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 23\u001B[1;33m     \u001B[0mvalid_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalid_acc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mms\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfederated_model\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     24\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mvalid_loss\u001B[0m \u001B[1;33m<\u001B[0m \u001B[0mbest_valid_loss\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-5-664007c2bfad>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     21\u001B[0m     \u001B[0mfederated_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mms\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfederated_averaging\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfed_models\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlen_model\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[1;31m# Validate this model on a, small balanced validation set\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 23\u001B[1;33m     \u001B[0mvalid_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalid_acc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mms\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfederated_model\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     24\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mvalid_loss\u001B[0m \u001B[1;33m<\u001B[0m \u001B[0mbest_valid_loss\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mD:\\Programs\\JetBrains\\PyCharm 2020.3.3\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1139\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1140\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1141\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1142\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1143\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Programs\\JetBrains\\PyCharm 2020.3.3\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1154\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1155\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1156\u001B[1;33m                 \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.01\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1157\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1158\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Here we train our federated model.\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(NUMBER_OF_EPOCHS):\n",
    "    # Perform the computation steps on the individual models\n",
    "    start_time = time.time()\n",
    "    for key, fed_model in fed_models.items():\n",
    "        # Update each model with the global model, before training again.\n",
    "        fed_model.model.load_state_dict(federated_model.state_dict())\n",
    "        fed_model.model.to(device=device)\n",
    "\n",
    "        # Begin training\n",
    "        optimizer = optim.Adam(fed_model.model.parameters())\n",
    "        train_loss, train_acc = ms.train(fed_model.model, fed_model.train_loader, optimizer, criterion, device=device)\n",
    "        valid_loss, valid_acc = ms.test(fed_model.model, fed_model.validation_loader, criterion, device=device)\n",
    "        print(f'Epoch: {epoch+1:02} | Model name: {key}')\n",
    "        print(f'\\tTrain Loss: {train_loss:.5f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.5f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    end_time = time.time()\n",
    "    # Get the time to perform federated learning\n",
    "    epoch_mins, epoch_secs = ms.epoch_time(start_time, end_time)\n",
    "\n",
    "    # Average the federated models and combine their weights into the main model.\n",
    "    len_model = len(train_loader.dataset)\n",
    "    federated_model.load_state_dict(ms.federated_averaging(fed_models, len_model))\n",
    "    # Validate this model on a, small balanced validation set\n",
    "    valid_loss, valid_acc = ms.test(federated_model, validation_loader, criterion, device=device)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        # This will save our best model in case we encounter a drop off during training.\n",
    "        torch.save(federated_model.state_dict(), 'best-model.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Model name: Federated Average | Epoch time (Federated Training): {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.5f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "print(\"Federated Model training complete.\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.000 | Test Acc: 99.01%\n"
     ]
    }
   ],
   "source": [
    "# The main testing loop\n",
    "# Load the model\n",
    "baseline_model.load_state_dict(torch.load(path))\n",
    "federated_model.load_state_dict(torch.load('best-model.pt'))\n",
    "\n",
    "baseline_test_loss, baseline_test_acc = ms.test(baseline_model, test_loader, criterion, device=device)\n",
    "fed_avg_test_loss, fed_avg_test_acc = ms.test(federated_model, test_loader, criterion, device=device)\n",
    "\n",
    "print(f'Model name: Baseline | Test Loss: {baseline_test_loss:.3f} | Test Acc: {baseline_test_acc*100:.2f}%')\n",
    "print(f'Model name: Federated Average | Test Loss: {fed_avg_test_loss:.3f} | Test Acc: {fed_avg_test_acc*100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}